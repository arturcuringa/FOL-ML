{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features:\n",
    "1. Fraction of clauses that are unit clauses. <!-- exactly one literal -->\n",
    "2. Fraction of clauses that are Horn clauses. <!-- at most one non-negated literal -->\n",
    "3. Fraction of clauses that are ground Clauses. <!-- ? -->\n",
    "4. Fraction of clauses that are demodulators. <!-- equality used as rule to rewrite newly inferred clause -->\n",
    "5. Fraction of clauses that are rewrite rules (oriented demodulators). <!-- ? -->\n",
    "6. Fraction of clauses that are purely positive.\n",
    "7. Fraction of clauses that are purely negative.\n",
    "8. Fraction of clauses that are mixed positive and negative.\n",
    "9. Maximum clause length. <!-- number of literals -->\n",
    "10. Average clause length.\n",
    "11. Maximum clause depth. <!-- see below -->\n",
    "12. Average clause depth.\n",
    "13. Maximum clause weight. <!-- defined by prover; probably its symbol count, excluding commas, parentheses, negation symbols, and disjunction symbols -->\n",
    "14. Average clause weight.\n",
    "\n",
    "<!-- \n",
    "Depth of Term, Atom, Literal, Clause\n",
    "* depth of variable, constant, or propositional atom: 0;\n",
    "* depth of term or atom with arguments: one more than the maximum argument depth;\n",
    "* depth of literal: depth of its atom (negation signs don't count);\n",
    "* depth of clause: maximum of depths of literals;\n",
    "* For example, p(x) | -p(f(x)) has depth 2.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.99682</td>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.76789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.16057</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73684</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.73872</td>\n",
       "      <td>0.073308</td>\n",
       "      <td>0.18797</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.99682</td>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77107</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>0.16057</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.74248</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.74436</td>\n",
       "      <td>0.067669</td>\n",
       "      <td>0.18797</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.99682</td>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.76789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.16057</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.74060</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.74248</td>\n",
       "      <td>0.069549</td>\n",
       "      <td>0.18797</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.99682</td>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.76789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.16057</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72932</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.73120</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.18797</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.99682</td>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.76789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.16057</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73120</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.73308</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.18797</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1        2        3   4        5         6        7   8   \\\n",
       "0  0.83307  0.99682  0.83307  0.76789   0  0.76948  0.069952  0.16057   6   \n",
       "1  0.83307  0.99682  0.83307  0.76948   0  0.77107  0.068363  0.16057   6   \n",
       "2  0.83307  0.99682  0.83307  0.76789   0  0.76948  0.069952  0.16057   6   \n",
       "3  0.83307  0.99682  0.83307  0.76789   0  0.76948  0.069952  0.16057   6   \n",
       "4  0.83307  0.99682  0.83307  0.76789   0  0.76948  0.069952  0.16057   6   \n",
       "\n",
       "       9    ...         48       49       50        51       52      53  \\\n",
       "0  1.2734   ...    0.73684  0.00188  0.73872  0.073308  0.18797 -100.00   \n",
       "1  1.2734   ...    0.74248  0.00188  0.74436  0.067669  0.18797    0.08   \n",
       "2  1.2734   ...    0.74060  0.00188  0.74248  0.069549  0.18797 -100.00   \n",
       "3  1.2734   ...    0.72932  0.00188  0.73120  0.080827  0.18797 -100.00   \n",
       "4  1.2734   ...    0.73120  0.00188  0.73308  0.078947  0.18797 -100.00   \n",
       "\n",
       "       54     55      56      57  \n",
       "0 -100.00 -100.0 -100.00 -100.00  \n",
       "1    0.08    0.2    0.08    0.08  \n",
       "2 -100.00 -100.0 -100.00 -100.00  \n",
       "3 -100.00 -100.0 -100.00 -100.00  \n",
       "4 -100.00 -100.0 -100.00 -100.00  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/all-data-raw.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       53      54     55      56      57\n",
      "0 -100.00 -100.00 -100.0 -100.00 -100.00\n",
      "1    0.08    0.08    0.2    0.08    0.08\n",
      "2 -100.00 -100.00 -100.0 -100.00 -100.00\n",
      "3 -100.00 -100.00 -100.0 -100.00 -100.00\n",
      "4 -100.00 -100.00 -100.0 -100.00 -100.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>heuristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.99682</td>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.76789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.16057</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.80639</td>\n",
       "      <td>0.99624</td>\n",
       "      <td>0.80263</td>\n",
       "      <td>0.73684</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.73872</td>\n",
       "      <td>0.073308</td>\n",
       "      <td>0.18797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.99682</td>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77107</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>0.16057</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.80639</td>\n",
       "      <td>0.99624</td>\n",
       "      <td>0.80263</td>\n",
       "      <td>0.74248</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.74436</td>\n",
       "      <td>0.067669</td>\n",
       "      <td>0.18797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.99682</td>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.76789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.16057</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.80639</td>\n",
       "      <td>0.99624</td>\n",
       "      <td>0.80263</td>\n",
       "      <td>0.74060</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.74248</td>\n",
       "      <td>0.069549</td>\n",
       "      <td>0.18797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.99682</td>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.76789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.16057</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.80639</td>\n",
       "      <td>0.99624</td>\n",
       "      <td>0.80263</td>\n",
       "      <td>0.72932</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.73120</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.18797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.99682</td>\n",
       "      <td>0.83307</td>\n",
       "      <td>0.76789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.16057</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.80639</td>\n",
       "      <td>0.99624</td>\n",
       "      <td>0.80263</td>\n",
       "      <td>0.73120</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.73308</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.18797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3  4        5         6        7  8  \\\n",
       "0  0.83307  0.99682  0.83307  0.76789  0  0.76948  0.069952  0.16057  6   \n",
       "1  0.83307  0.99682  0.83307  0.76948  0  0.77107  0.068363  0.16057  6   \n",
       "2  0.83307  0.99682  0.83307  0.76789  0  0.76948  0.069952  0.16057  6   \n",
       "3  0.83307  0.99682  0.83307  0.76789  0  0.76948  0.069952  0.16057  6   \n",
       "4  0.83307  0.99682  0.83307  0.76789  0  0.76948  0.069952  0.16057  6   \n",
       "\n",
       "        9    ...            44       45       46       47       48       49  \\\n",
       "0  1.2734    ...      0.020202  0.80639  0.99624  0.80263  0.73684  0.00188   \n",
       "1  1.2734    ...      0.020202  0.80639  0.99624  0.80263  0.74248  0.00188   \n",
       "2  1.2734    ...      0.020202  0.80639  0.99624  0.80263  0.74060  0.00188   \n",
       "3  1.2734    ...      0.020202  0.80639  0.99624  0.80263  0.72932  0.00188   \n",
       "4  1.2734    ...      0.020202  0.80639  0.99624  0.80263  0.73120  0.00188   \n",
       "\n",
       "        50        51       52  heuristic  \n",
       "0  0.73872  0.073308  0.18797          0  \n",
       "1  0.74436  0.067669  0.18797          1  \n",
       "2  0.74248  0.069549  0.18797          0  \n",
       "3  0.73120  0.080827  0.18797          0  \n",
       "4  0.73308  0.078947  0.18797          0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_times = df.iloc[:, -5:]\n",
    "print(h_times.head())\n",
    "\n",
    "import numpy as np\n",
    "def best_heuristic(row):\n",
    "    n_heuristics = 5\n",
    "    h_times = row[-n_heuristics:].reset_index(drop=True)\n",
    "    h_times.replace({-100.0 : np.nan}, inplace=True)\n",
    "    idx, min_time = h_times.idxmin(), h_times.min()\n",
    "    if np.isnan(min_time):\n",
    "       return 0\n",
    "    else:\n",
    "       return idx+1\n",
    "\n",
    "df['heuristic'] = df.apply(best_heuristic, axis=1)\n",
    "df.drop([53, 54, 55, 56, 57], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2554\n",
       "1    1089\n",
       "3     748\n",
       "5     624\n",
       "4     617\n",
       "2     486\n",
       "Name: heuristic, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['heuristic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-e618c515317b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mknn_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mval_col_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X, y = df.drop(['heuristic'], axis=1).astype('float64'), df['heuristic']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=44)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'classifier__n_neighbors': range(1,15),\n",
    "    'classifier__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(10, shuffle=True, random_state=42)\n",
    "knn_grid = GridSearchCV(pipe, params, scoring='accuracy', cv=kfold, verbose=1, n_jobs=-1)\n",
    "knn_grid.fit(X, y)\n",
    "\n",
    "print(knn_grid.best_params_)\n",
    "\n",
    "val_col_space = 20\n",
    "print(\"{:{}}: {:.4f}\".format(\"10-fold CV\", val_col_space, knn_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__n_neighbors': 12, 'classifier__weights': 'distance'}\n",
      "10-fold CV          : 0.6036\n"
     ]
    }
   ],
   "source": [
    "print(knn_grid.best_params_)\n",
    "val_col_space = 20\n",
    "print(\"{:{}}: {:.4f}\".format(\"10-fold CV\", val_col_space, knn_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/carlosv/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.1021359 , 0.05731089, 0.07179599, 0.06776688, 0.066731  ,\n",
       "        0.0665082 , 0.06477678, 0.06517074, 0.06712677, 0.06862223,\n",
       "        0.06526237, 0.06904685, 0.06701689, 0.06774733, 0.06505749,\n",
       "        0.06624551, 0.06955681, 0.06706414, 0.06563666, 0.06473808,\n",
       "        0.06790586, 0.06899359, 0.06533141, 0.0688319 , 0.06593912,\n",
       "        0.06330769, 0.06838744, 0.07005229]),\n",
       " 'std_fit_time': array([0.04052453, 0.01193452, 0.0051924 , 0.00260733, 0.00475699,\n",
       "        0.00366516, 0.00665532, 0.00647001, 0.01259429, 0.00478825,\n",
       "        0.00891787, 0.00445975, 0.00541554, 0.00596335, 0.00550141,\n",
       "        0.00508964, 0.00953098, 0.00315979, 0.00560787, 0.00888291,\n",
       "        0.00508041, 0.0036896 , 0.00710937, 0.00616511, 0.00947686,\n",
       "        0.00923715, 0.00281709, 0.00325507]),\n",
       " 'mean_score_time': array([0.1313055 , 0.11531773, 0.18309433, 0.181218  , 0.20303285,\n",
       "        0.19797404, 0.20172992, 0.217187  , 0.22107725, 0.22898333,\n",
       "        0.28980911, 0.24118516, 0.25160797, 0.24339459, 0.25965068,\n",
       "        0.25860567, 0.27238991, 0.26177666, 0.2709579 , 0.27011755,\n",
       "        0.28304486, 0.28077927, 0.27999105, 0.28287783, 0.27909031,\n",
       "        0.27156541, 0.30065234, 0.3101495 ]),\n",
       " 'std_score_time': array([0.01966721, 0.02693894, 0.01556818, 0.0144945 , 0.01229344,\n",
       "        0.0082395 , 0.03375142, 0.00937451, 0.03211742, 0.00667113,\n",
       "        0.08529362, 0.01806665, 0.01400025, 0.0283989 , 0.02027175,\n",
       "        0.01499876, 0.02418007, 0.01250652, 0.01011628, 0.02441001,\n",
       "        0.02114169, 0.01131663, 0.01645803, 0.01452757, 0.03104364,\n",
       "        0.04930888, 0.01071942, 0.01755531]),\n",
       " 'param_classifier__n_neighbors': masked_array(data=[1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__n_neighbors': 1, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 1, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 2, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 2, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 3, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 4, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 4, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 5, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 5, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 6, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 6, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 7, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 7, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 8, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 8, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 9, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 9, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 10, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 10, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 11, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 11, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 12, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 12, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 13, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 13, 'classifier__weights': 'distance'},\n",
       "  {'classifier__n_neighbors': 14, 'classifier__weights': 'uniform'},\n",
       "  {'classifier__n_neighbors': 14, 'classifier__weights': 'distance'}],\n",
       " 'split0_test_score': array([0.58794788, 0.58794788, 0.58469055, 0.58957655, 0.56840391,\n",
       "        0.59609121, 0.55863192, 0.59771987, 0.56188925, 0.59771987,\n",
       "        0.57166124, 0.61237785, 0.58143322, 0.60586319, 0.57003257,\n",
       "        0.60749186, 0.57654723, 0.61400651, 0.57491857, 0.61237785,\n",
       "        0.58143322, 0.61237785, 0.5732899 , 0.61563518, 0.56677524,\n",
       "        0.61563518, 0.56351792, 0.61400651]),\n",
       " 'split1_test_score': array([0.59283388, 0.59283388, 0.56514658, 0.59771987, 0.55211726,\n",
       "        0.59771987, 0.56840391, 0.6009772 , 0.56188925, 0.6009772 ,\n",
       "        0.54397394, 0.59609121, 0.54885993, 0.59771987, 0.54885993,\n",
       "        0.60260586, 0.53583062, 0.59120521, 0.53583062, 0.59446254,\n",
       "        0.54397394, 0.58957655, 0.53908795, 0.59283388, 0.52442997,\n",
       "        0.58631922, 0.53094463, 0.58469055]),\n",
       " 'split2_test_score': array([0.58794788, 0.58794788, 0.57654723, 0.58794788, 0.5781759 ,\n",
       "        0.59446254, 0.56026059, 0.58631922, 0.54723127, 0.59120521,\n",
       "        0.55211726, 0.59446254, 0.54397394, 0.58631922, 0.55863192,\n",
       "        0.58631922, 0.56677524, 0.59771987, 0.56514658, 0.59771987,\n",
       "        0.5504886 , 0.59120521, 0.54397394, 0.6009772 , 0.54397394,\n",
       "        0.59609121, 0.54560261, 0.59934853]),\n",
       " 'split3_test_score': array([0.59120521, 0.59120521, 0.59283388, 0.58469055, 0.56188925,\n",
       "        0.60586319, 0.56514658, 0.59609121, 0.54723127, 0.59120521,\n",
       "        0.54234528, 0.6009772 , 0.53908795, 0.59446254, 0.5504886 ,\n",
       "        0.58469055, 0.56026059, 0.59609121, 0.5504886 , 0.58794788,\n",
       "        0.55863192, 0.6009772 , 0.54723127, 0.59609121, 0.54397394,\n",
       "        0.6009772 , 0.53094463, 0.58957655]),\n",
       " 'split4_test_score': array([0.55228758, 0.55228758, 0.54248366, 0.55555556, 0.54084967,\n",
       "        0.55882353, 0.53921569, 0.55882353, 0.55392157, 0.56372549,\n",
       "        0.55392157, 0.57189542, 0.54575163, 0.57026144, 0.5620915 ,\n",
       "        0.56862745, 0.55228758, 0.57026144, 0.54248366, 0.56535948,\n",
       "        0.54575163, 0.56372549, 0.54575163, 0.57026144, 0.54901961,\n",
       "        0.57189542, 0.55228758, 0.57189542]),\n",
       " 'split5_test_score': array([0.61111111, 0.61111111, 0.60130719, 0.60784314, 0.57679739,\n",
       "        0.60784314, 0.56045752, 0.59803922, 0.58660131, 0.60947712,\n",
       "        0.57352941, 0.61928105, 0.56699346, 0.61764706, 0.56862745,\n",
       "        0.61437908, 0.55555556, 0.61601307, 0.55392157, 0.60784314,\n",
       "        0.54575163, 0.61111111, 0.54738562, 0.60457516, 0.54411765,\n",
       "        0.60457516, 0.53431373, 0.60620915]),\n",
       " 'split6_test_score': array([0.58265139, 0.58265139, 0.58592471, 0.58265139, 0.58919804,\n",
       "        0.60392799, 0.57283142, 0.60883797, 0.57283142, 0.59574468,\n",
       "        0.57446809, 0.59574468, 0.58756137, 0.60065466, 0.59247136,\n",
       "        0.599018  , 0.58265139, 0.60392799, 0.5695581 , 0.60392799,\n",
       "        0.58101473, 0.60883797, 0.57610475, 0.6202946 , 0.56628478,\n",
       "        0.61374795, 0.5695581 , 0.61538462]),\n",
       " 'split7_test_score': array([0.58852459, 0.58852459, 0.59344262, 0.58688525, 0.58196721,\n",
       "        0.61803279, 0.59016393, 0.60983607, 0.58852459, 0.60819672,\n",
       "        0.58360656, 0.6147541 , 0.56721311, 0.61803279, 0.56885246,\n",
       "        0.60983607, 0.56557377, 0.6147541 , 0.5704918 , 0.61803279,\n",
       "        0.57213115, 0.62622951, 0.5557377 , 0.61803279, 0.5557377 ,\n",
       "        0.62459016, 0.55409836, 0.62459016]),\n",
       " 'split8_test_score': array([0.58784893, 0.58784893, 0.55829228, 0.58949097, 0.55829228,\n",
       "        0.58784893, 0.58128079, 0.59934319, 0.55829228, 0.59277504,\n",
       "        0.55993432, 0.591133  , 0.57142857, 0.59934319, 0.56978654,\n",
       "        0.60262726, 0.57307061, 0.60591133, 0.55172414, 0.60426929,\n",
       "        0.54844007, 0.59605911, 0.55665025, 0.60262726, 0.56321839,\n",
       "        0.60098522, 0.56157635, 0.59605911]),\n",
       " 'split9_test_score': array([0.60690789, 0.60690789, 0.58388158, 0.62335526, 0.58388158,\n",
       "        0.62828947, 0.5625    , 0.60526316, 0.56743421, 0.61677632,\n",
       "        0.55427632, 0.62006579, 0.55592105, 0.61842105, 0.56085526,\n",
       "        0.61677632, 0.53453947, 0.62171053, 0.54769737, 0.62335526,\n",
       "        0.55427632, 0.62006579, 0.55427632, 0.61513158, 0.54605263,\n",
       "        0.60855263, 0.54769737, 0.61513158]),\n",
       " 'mean_test_score': array([0.58891795, 0.58891795, 0.57845701, 0.59055247, 0.56914024,\n",
       "        0.59986924, 0.5658712 , 0.59610984, 0.56456358, 0.59676365,\n",
       "        0.56096764, 0.60166721, 0.56080418, 0.60084995, 0.56505394,\n",
       "        0.59921543, 0.56031383, 0.60313828, 0.55622753, 0.60150376,\n",
       "        0.55818895, 0.60199412, 0.5539392 , 0.60362864, 0.55034325,\n",
       "        0.60232102, 0.54903563, 0.60166721]),\n",
       " 'std_test_score': array([0.01489828, 0.01489828, 0.01719973, 0.0166261 , 0.01477928,\n",
       "        0.01767817, 0.01309833, 0.01400123, 0.01380033, 0.01370961,\n",
       "        0.01333172, 0.0143128 , 0.01576334, 0.01452448, 0.0116998 ,\n",
       "        0.01433676, 0.01530728, 0.01439933, 0.01244246, 0.01573107,\n",
       "        0.01392185, 0.0170908 , 0.01163321, 0.01434252, 0.0123813 ,\n",
       "        0.01439436, 0.01308103, 0.0155716 ]),\n",
       " 'rank_test_score': array([14, 14, 16, 13, 17,  9, 18, 12, 20, 11, 21,  5, 22,  8, 19, 10, 23,\n",
       "         2, 25,  7, 24,  4, 26,  1, 27,  3, 28,  5], dtype=int32),\n",
       " 'split0_train_score': array([0.97547238, 0.97547238, 0.7916061 , 0.97565407, 0.75345203,\n",
       "        0.97710756, 0.71420785, 0.97747093, 0.68986192, 0.97765262,\n",
       "        0.67296512, 0.97747093, 0.66188227, 0.97765262, 0.64534884,\n",
       "        0.97765262, 0.62899709, 0.97765262, 0.62191134, 0.97765262,\n",
       "        0.61518895, 0.97765262, 0.60701308, 0.97765262, 0.60483285,\n",
       "        0.97765262, 0.60010901, 0.97765262]),\n",
       " 'split1_train_score': array([0.97583576, 0.97583576, 0.78960756, 0.97583576, 0.75436047,\n",
       "        0.97674419, 0.71947674, 0.97710756, 0.69349564, 0.97728924,\n",
       "        0.67823401, 0.97728924, 0.66115552, 0.97728924, 0.64516715,\n",
       "        0.97728924, 0.63917151, 0.97728924, 0.63135901, 0.97728924,\n",
       "        0.62318314, 0.97728924, 0.61573401, 0.97728924, 0.60919331,\n",
       "        0.97728924, 0.60483285, 0.97728924]),\n",
       " 'split2_train_score': array([0.97801599, 0.97801599, 0.79015262, 0.97710756, 0.75436047,\n",
       "        0.97874273, 0.71311773, 0.97892442, 0.69022529, 0.9791061 ,\n",
       "        0.6744186 , 0.9791061 , 0.66424419, 0.9791061 , 0.65134448,\n",
       "        0.9791061 , 0.64080669, 0.9791061 , 0.63390262, 0.9791061 ,\n",
       "        0.62590843, 0.9791061 , 0.61337209, 0.9791061 , 0.609375  ,\n",
       "        0.9791061 , 0.60773983, 0.9791061 ]),\n",
       " 'split3_train_score': array([0.97638081, 0.97638081, 0.79106105, 0.97710756, 0.75617733,\n",
       "        0.97837936, 0.71547965, 0.97837936, 0.68968023, 0.97819767,\n",
       "        0.67478198, 0.97874273, 0.6627907 , 0.97874273, 0.64698401,\n",
       "        0.97874273, 0.64098837, 0.97874273, 0.63135901, 0.97874273,\n",
       "        0.62281977, 0.97874273, 0.61609738, 0.97874273, 0.60356105,\n",
       "        0.97874273, 0.60337936, 0.97874273]),\n",
       " 'split4_train_score': array([0.97366509, 0.97366509, 0.79113694, 0.97439157, 0.75826371,\n",
       "        0.97693425, 0.7210316 , 0.97711587, 0.69705776, 0.97693425,\n",
       "        0.67617145, 0.97693425, 0.66291319, 0.97711587, 0.65001816,\n",
       "        0.97711587, 0.64111878, 0.97711587, 0.63439884, 0.97711587,\n",
       "        0.62277515, 0.97711587, 0.61732655, 0.97711587, 0.61387577,\n",
       "        0.97711587, 0.60988013, 0.97711587]),\n",
       " 'split5_train_score': array([0.97529967, 0.97529967, 0.78823102, 0.97529967, 0.75118053,\n",
       "        0.97766073, 0.7137668 , 0.97784235, 0.69088267, 0.97784235,\n",
       "        0.67598983, 0.97784235, 0.6594624 , 0.97784235, 0.64820196,\n",
       "        0.97784235, 0.63476208, 0.97784235, 0.6294951 , 0.97784235,\n",
       "        0.62549946, 0.97784235, 0.61605521, 0.97784235, 0.61278605,\n",
       "        0.97784235, 0.60806393, 0.97784235]),\n",
       " 'split6_train_score': array([0.97730162, 0.97730162, 0.78954058, 0.97693844, 0.75177047,\n",
       "        0.97802796, 0.71454512, 0.97857273, 0.69311785, 0.97857273,\n",
       "        0.67368803, 0.97857273, 0.65571091, 0.97875431, 0.65008171,\n",
       "        0.97875431, 0.63755221, 0.97875431, 0.62629381, 0.97875431,\n",
       "        0.61739604, 0.97875431, 0.61539858, 0.97875431, 0.60504812,\n",
       "        0.97875431, 0.60159797, 0.97875431]),\n",
       " 'split7_train_score': array([0.97458243, 0.97458243, 0.7899419 , 0.97494553, 0.75363108,\n",
       "        0.97639797, 0.71514161, 0.97676107, 0.68917938, 0.97676107,\n",
       "        0.67392883, 0.97676107, 0.65740741, 0.97694263, 0.64342774,\n",
       "        0.97694263, 0.63271605, 0.97694263, 0.6328976 , 0.97694263,\n",
       "        0.62418301, 0.97694263, 0.61528686, 0.97694263, 0.61401598,\n",
       "        0.97694263, 0.60566449, 0.97694263]),\n",
       " 'split8_train_score': array([0.97567617, 0.97567617, 0.79252133, 0.97476856, 0.75549101,\n",
       "        0.97676529, 0.71827918, 0.97658377, 0.69322926, 0.97658377,\n",
       "        0.67671084, 0.97676529, 0.66418588, 0.97676529, 0.65220548,\n",
       "        0.97676529, 0.64058813, 0.97676529, 0.62770013, 0.97676529,\n",
       "        0.61826103, 0.97676529, 0.61317844, 0.97676529, 0.60864041,\n",
       "        0.97676529, 0.60029043, 0.97676529]),\n",
       " 'split9_train_score': array([0.97186933, 0.97186933, 0.79056261, 0.97586207, 0.75099819,\n",
       "        0.97568058, 0.71161525, 0.97622505, 0.69147005, 0.976951  ,\n",
       "        0.67186933, 0.976951  , 0.6569873 , 0.97713249, 0.64446461,\n",
       "        0.97713249, 0.63575318, 0.97713249, 0.63194192, 0.97713249,\n",
       "        0.62250454, 0.97713249, 0.6154265 , 0.97713249, 0.60816697,\n",
       "        0.97713249, 0.60544465, 0.97713249]),\n",
       " 'mean_train_score': array([0.97540992, 0.97540992, 0.79043617, 0.97579108, 0.75396853,\n",
       "        0.97724406, 0.71566615, 0.97749831, 0.69182001, 0.97758908,\n",
       "        0.6748758 , 0.97764357, 0.66067398, 0.97773436, 0.64772441,\n",
       "        0.97773436, 0.63724541, 0.97773436, 0.63012594, 0.97773436,\n",
       "        0.62177195, 0.97773436, 0.61448887, 0.97773436, 0.60894955,\n",
       "        0.97773436, 0.60470026, 0.97773436]),\n",
       " 'std_train_score': array([0.00166871, 0.00166871, 0.00115283, 0.00093643, 0.00218542,\n",
       "        0.00089873, 0.00283446, 0.00085928, 0.00229874, 0.00079559,\n",
       "        0.00181052, 0.00083297, 0.00294327, 0.00080411, 0.00293343,\n",
       "        0.00080411, 0.0039194 , 0.00080411, 0.00367409, 0.00080411,\n",
       "        0.00340971, 0.00080411, 0.00275389, 0.00080411, 0.00356101,\n",
       "        0.00080411, 0.0031746 , 0.00080411])}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
